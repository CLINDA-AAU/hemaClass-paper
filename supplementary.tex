\documentclass{article}
\input{preamble}
\begin{document}

% Prefix S to figures, tables, etc
\renewcommand{\theequation}{S\arabic{equation}}
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}
\renewcommand{\thesection}{S\arabic{section}}

% reset counters
\setcounter{section}{0}
\setcounter{subsection}{0}
\setcounter{equation}{0}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{page}{1}


\phantomsection
\addcontentsline{toc}{section}{Supplementary Material}
\begin{center}
{\huge SUPPLEMENTARY MATERIAL}\bigskip \\
{\bf \hemaClassTitle{}}
\end{center}

\section{Supplementary figures and tables}
This section holds the supplementary figures and tables.

\begin{figure*}[htb]
\begin{center}
\includegraphics[width=1\textwidth]{figures/CrosvalidationClass.pdf}
\end{center}
\caption{Ten fold cross validation for the parameters $\alpha$ and $\lambda$ in a logistic regression regularized by elastic net.
In panels A and B the deviance is plotted against the model parameter $\alpha$ and regularization parameter $\lambda$, respectively.
In Panel C the regularization curves are shown.
Black and grey curves represent selected and non-selected probe-sets, respectively.
Positive and negative coefficients indicate that high expression values for the associated gene are related to ABC and GCB, respectively.
The red line indicates the model chosen through $10$ fold cross validation.
The gene symbols for the $20$ probe-sets associated with the largest absolute coefficients in the chosen gene expression predictors are displayed in Panel C.}
\label{fig:crossval}
\end{figure*}

\input{tables/tableS1.tex}
\input{tables/tableS2.tex}
\input{tables/tableS3.tex}
\input{tables/tableS4.tex}
\clearpage



\section{Graham's formula}
\label{sec:graham}
This section derives Graham's formula which, in our context, yields the posterior probability of being resistance to the combination of two drugs, given resistance to the individual drugs.
For simplicity, the formula is derived for two drugs.
The formula straightforwardly generalizes to three or more drugs.

Let $C$, $H$, and $B$ be Bernoulli distributed random variables with probability parameter $1/2$, where
$C = 1$ indicates resistance to Cyclophosphamide $C$,
$H = 1$ indicates resistance to Doxorubicin $H$, and
$B = 1$ indicates resistance to the combination of $H$ and $C$.
Conversely, $C,H,$ and $B = 0$ indicate sensitivity towards $C,H,$ and $B$, respectively.
Under an assumption of conditional drug independence
\begin{align*}
  P(C=1, H=1| B=1) &= P(C=1 | B=1) P(H=1 | B=1), \text{ and } \\
  P(C=1, H=1| B=0) &= P(C=1 | B=0) P(H=1 | B=0)
\end{align*}
we have that
\begin{align*}
  &P(B=1 | H=1, C=1)
  \\&\qquad
   = \frac{P(C=1, H=1, B=1)}
          {P(C=1, H=1)}
  \\&\qquad
   = \frac{P(C=1, H=1 | B=1) P(B=1)}
          {P(C=1, H=1, B=1) + P(C=1, H=1, B=0)}
  \\&\qquad
   = \frac{P(C=1 | B=1) P(H=1 | B=1) P(B=1)}
          {P(C=1, H=1 | B=1) P(B=1) + P(H=1, C=1| B=0) P(B=0)},
\end{align*}
by the definition of conditional probabilities, the law of total probability, and the assumptions.
From the distributional assumption on $B$, $P(B=0) = P(B=1) = 1/2$, and the above then simplifies to:
\begin{equation*}
  P(B=1 | H=1, C=1)
   = \frac{P(C=1 | B=1) P(H=1 | B=1)}
          {P(C=1, H=1 | B=1) + P(H=1, C=1 | B=0)}.
\end{equation*}
For notational convenience, we abbreviate
$P_C = P(C=1 | B=1)$,
$P_H = P(H=1 | B=1)$,
$P_{CH} = P(B=1 | H=1, C=1)$.
The distributional assumptions then imply:
\begin{align*}
  P_{CH}
  &= \frac{P_C P_H}
          {P_C P_H + P(C=1 | B=0) P(H=1 | B=0)}
  \\
  &= \frac{P_C P_H}
          {P_C P_H + P(B=0 | C=1) P(B=0 | H=1)}
  \\
  &= \frac{P_C P_H}
          {P_C P_H + \bigl(1 - P(B=1 | C=1)\bigr)\bigl(1 - P(B=1 | H=1)\bigr)}
  \\
  &= \frac{P_C P_H}
          {P_C P_H + (1 - P_C)(1 - P_H)},
\end{align*}
which is the two-drug equivalent to the used formula.




\section{RMA normalization}
Recall that ordinary robust multichip average (RMA) pre-processing consists of three steps: (1) Background adjustment, (2) quantile normalization, and (3) summarization of probes to probe-sets, see e.g.\ \citep{Irizarry2003, Irizarry2003b}. For completeness we review ordinary cohort based RMA normalization.

\subsection{Backgroud correction}
In order to produce background adjusted probe intensities we will use the within array normal-exponential de-convolution scheme as implemented by the \texttt{rma.background.correct} command in the Bioconductor package \texttt{preprocessCores}, see
\citep{Irizarry2003b,Bolstad2004}.


\subsection{Quantile normalization}
Let $x_{ijk}$ be the $\log_2$-transformed and background adjusted cohort data, where $i = 1,\dots,I$ index the arrays of the cohort data, $j=1,\dots,J$  index the probe-sets, and $k=1,\dots,K_j$ index the probes nested within probe-sets.

Furthermore, let $G_i$ denote the empirical cumulative distribution function (ECDF) of the probes $\{x_{ijk}\}_{jk}$ on the $i$'th cohort array and $F$ the ECDF of the across array averaged sample quantiles $\{\bar{x}_{\cdot (jk)}\}_{ij}$, where $\{x_{i(jk)}\}_{jk}$ is the order statistic of all probes on the $i$'th cohort array based on the lexicographic ordering of the indices $\{jk\}$. Then each data point is quantile normalized in the following way
\begin{equation*}
     \tilde{x}_{ijk} = F^{-1}(G_i(x_{ijk})),
\end{equation*}
where $F^{-1}$ is calculated as the quantiles of type 2 \citep{Hyndman1996}.
This step is performed by the \texttt{RMA\_norm} function with option \texttt{generateQuan} equal to one in the \texttt{hemaClass} package.

\subsection{Summarisation}

For each probe-set $j$ we let $\mu_{ij}$ represent the $\log_2$-scale expression level for array $i$ and probeset $j$, $\alpha_{jk}$ the probe affinity effect, and the $\epsilon_{ijk}$'s are independent identically distributed  error terms with mean 0 and formulate the following linear additive model
\begin{equation*}
   \tilde{x}_{ijk} = \mu_{ij} + \alpha_{jk}+ \epsilon_{ijk},
\end{equation*}
where $\sum_{k=0}^{n_j} \alpha_{jk} = 0$ for all probe-sets. The parameters are estimated by median polish \citep{Holder2001}. The probe affinity estimates are denoted by $\hat{\alpha}_{jk}$.

The RMA normalized cohort data are given by
\begin{equation*}
   \hat{x}_{ij\cdot} = \hat{\mu}_{ij}.
\end{equation*}
This step is performed by the \texttt{RMA\_sum} function in the \hemaClass{} package.

\section{One-by-one RMA normalization of user supplied data}
\subsection{Backgroud correction}
The background correction in one-by-one RMA normalization is unaltered as it is already works in a one-by-one fashion.



\subsection{Quantile normalization}

Let $x_{ijk}$ be the $\log_2$-transformed and background corrected reference data, where $i = 1,\dots,I_R$ index the arrays of the reference data, $j=1,\dots,J$  index the probe-sets, and $k=1,\dots,K_j$ index the probes. Assume $x_{ijk}$ has been RMA normalized as described above. Similarly,  let $y_{ijk}$ be the log2-transformed and background corrected user supplied data, where $i = 1,\dots,I_U$ index the arrays of the user supplied data, $j=1,\dots,J$  index the probe-sets, and $k=1,\dots,K_j$ index the probes. Furthermore, let $H_i$ denote the ECDF of the user supplied data $\{y_{ijk}\}_{jk}$.

As quantile normalizer the ECDF of the background corrected reference data is used in place of the ususally applied ECDF of the mean of the sample quantiles
\begin{equation*}
   \tilde{y}_{ijk} = F^{-1}(H_i(y_{ijk})).
\end{equation*}
This step is performed by the \texttt{RMA\_norm} function with options \texttt{generateQuan} equal to zero and \texttt{quantile} equal to the quantiles of the reference data in the \texttt{hemaClass} package.


\subsection{Summarisation}
To mimic the RMA summarization the probe effects estimated by median polish on the reference data is subtracted all probes of the user data
\begin{equation*}
   \hat{y}_{ijk} = \tilde{y}_{ijk} - \hat{\alpha}_{jk}.
\end{equation*}
The pre-processed expression value for each probe-set is then estimated as the median of the associated probes.
\begin{equation*}
   \hat{y}_{ij\cdot} = \median_{k \in \{1,\dots,n_j \}} \{ \hat{y}_{ijk} \}.
\end{equation*}


\section{Classification}
To ensure identical classification probabilities whether data is supplied as a cohort or one-by-one, we finally subtract the median of each probe-set in the reference from the corresponding probe-set and scaled by the standard deviation of each probe-set in the reference data
\begin{equation*}
  (\hat{y}_{ij\cdot} - \hat{x}_{\cdot j\cdot})/s_{\cdot j\cdot},
\end{equation*}
where
$\hat{x}_{\cdot j\cdot} = \median_{i \in \{1,\dots,I_R \}} \{\hat{x}_{ij\cdot}\}$ and $s_{\cdot j\cdot} = \std_{i \in \{1,\dots,I_R\}} \{\hat{x}_{ij\cdot}\}$.





\phantomsection
\addcontentsline{toc}{section}{References}
\bibliographystyle{plainnat} %abbrvnat
\bibliography{references}

\end{document}
